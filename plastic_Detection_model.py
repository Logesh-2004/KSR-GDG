# -*- coding: utf-8 -*-
"""RIC'24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uOisjvPalDGCYyMR9KXCnOGXNpcRfEYo
"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="6O1FpH8fM66coiML79yt")
project = rf.workspace("dhivakar").project("plastic-detection-in-ocean-zqbuy-g7p57-a8hvq")
version = project.version(1)
dataset = version.download("yolov5")

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torchvision.models as models
from PIL import Image
import pandas as pd
import os
import glob  # Import glob to find files

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
num_epochs = 20
batch_size = 64
learning_rate = 0.001
num_classes = 15  # Adjust based on your dataset

# Define custom dataset
class CustomImageDataset(Dataset):
    def __init__(self, img_dir, label_dir, transform=None):
        # Get all image paths
        self.img_paths = glob.glob(os.path.join(img_dir, "*.jpg"))  # Adjust file extension if needed
        self.label_dir = label_dir
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        image = Image.open(img_path).convert("RGB")

        # Construct label file path
        label_file_name = os.path.basename(img_path).replace(".jpg", ".txt")  # Adjust file extensions if needed
        label_file_path = os.path.join(self.label_dir, label_file_name)

        # Read label from text file (assuming YOLO format)
        with open(label_file_path, "r") as f:
            label = int(f.readline().split()[0])  # Get the first element (class ID)

        if self.transform:
            image = self.transform(image)

        return image, label

# Image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
train_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/train/images', label_dir='/content/Plastic-Detection-in-ocean-1/train/labels', transform=transform)
val_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/valid/images', label_dir='/content/Plastic-Detection-in-ocean-1/valid/labels', transform=transform)
test_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/test/images', label_dir='/content/Plastic-Detection-in-ocean-1/test/labels', transform=transform)

# ... (Rest of the code remains the same)

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

# Load the pretrained ResNet-50 model and adjust final layer
model = models.resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

# Loss, optimizer, and learning rate scheduler
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

# Training function
def train_model(model, train_loader, val_loader, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

        # Validation phase (if needed)
        model.eval()
        # Add validation code here if desired

# Train the model
train_model(model, train_loader, val_loader, num_epochs)

# After training the model
torch.save(model.state_dict(), 'resnet50_model.pt')  # Save the model
print("Model saved as resnet50_model.pt")

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torchvision.models as models
from PIL import Image
import pandas as pd
import os
import glob  # Import glob to find files
import matplotlib.pyplot as plt  # Import matplotlib for plotting

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
num_epochs = 20
batch_size = 64
learning_rate = 0.001
num_classes = 15  # Adjust based on your dataset

# Define custom dataset
class CustomImageDataset(Dataset):
    def __init__(self, img_dir, label_dir, transform=None):
        # Get all image paths
        self.img_paths = glob.glob(os.path.join(img_dir, "*.jpg"))  # Adjust file extension if needed
        self.label_dir = label_dir
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        image = Image.open(img_path).convert("RGB")

        # Construct label file path
        label_file_name = os.path.basename(img_path).replace(".jpg", ".txt")  # Adjust file extensions if needed
        label_file_path = os.path.join(self.label_dir, label_file_name)

        # Read label from text file (assuming YOLO format)
        with open(label_file_path, "r") as f:
            label = int(f.readline().split()[0])  # Get the first element (class ID)

        if self.transform:
            image = self.transform(image)

        return image, label

# Image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
train_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/train/images',
                                 label_dir='/content/Plastic-Detection-in-ocean-1/train/labels',
                                 transform=transform)
val_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/valid/images',
                               label_dir='/content/Plastic-Detection-in-ocean-1/valid/labels',
                               transform=transform)
test_data = CustomImageDataset(img_dir='/content/Plastic-Detection-in-ocean-1/test/images',
                                label_dir='/content/Plastic-Detection-in-ocean-1/test/labels',
                                transform=transform)

# DataLoader
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

# Load the pretrained ResNet-50 model and adjust final layer
model = models.resnet50(weights='IMAGENET1K_V1')  # Use the updated way to load pretrained weights
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

# Loss, optimizer, and learning rate scheduler
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

# Lists to store training loss and validation accuracy
train_losses = []
val_accuracies = []

# Training function
def train_model(model, train_loader, val_loader, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        epoch_loss = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_loss)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}")

        # Validation phase
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_accuracy = 100 * correct / total
        val_accuracies.append(val_accuracy)
        print(f'Validation Accuracy: {val_accuracy:.2f}%')

# Train the model
train_model(model, train_loader, val_loader, num_epochs)

# List of class names (ordered as in the dataset)
class_names = train_data.classes

# Example usage for a new image
def classify_new_image(model, image_path, class_names):
    model.eval()
    with torch.no_grad():
        image = Image.open(image_path).convert("RGB")
        image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device
        outputs = model(image)
        _, predicted = torch.max(outputs.data, 1)
        predicted_class = class_names[predicted.item()]
        print(f'The predicted class for the image is: {predicted_class}')

# Classify a new image (provide the correct path)
classify_new_image(model, '/content/Sample1.jpg', class_names)

# Plot training loss and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy over Epochs')
plt.legend()

plt.show()